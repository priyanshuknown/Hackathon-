{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":127058,"databundleVersionId":15217356,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-11T04:20:42.380066Z","iopub.execute_input":"2026-01-11T04:20:42.380393Z","iopub.status.idle":"2026-01-11T04:20:43.607994Z","shell.execute_reply.started":"2026-01-11T04:20:42.380335Z","shell.execute_reply":"2026-01-11T04:20:43.606993Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/bash-8-0-round-2/train.csv\n/kaggle/input/bash-8-0-round-2/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T04:20:43.610126Z","iopub.execute_input":"2026-01-11T04:20:43.610539Z","iopub.status.idle":"2026-01-11T04:20:53.192505Z","shell.execute_reply.started":"2026-01-11T04:20:43.610507Z","shell.execute_reply":"2026-01-11T04:20:53.191743Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n  if entities is not ():\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv(\"/kaggle/input/bash-8-0-round-2/train.csv\").fillna(\"\")\ntest_df  = pd.read_csv(\"/kaggle/input/bash-8-0-round-2/test.csv\").fillna(\"\")\n\n\nprint(\"Train shape:\", train_df.shape)\nprint(\"Test shape :\", test_df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T04:21:57.499065Z","iopub.execute_input":"2026-01-11T04:21:57.499467Z","iopub.status.idle":"2026-01-11T04:21:58.066180Z","shell.execute_reply.started":"2026-01-11T04:21:57.499436Z","shell.execute_reply":"2026-01-11T04:21:58.065278Z"}},"outputs":[{"name":"stdout","text":"Train shape: (20624, 10)\nTest shape : (5157, 9)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\n\nfor root, dirs, files in os.walk(\"/kaggle//input\"):\n    for file in files:\n        print(os.path.join(root, file))\ntrain_df.head()\ntrain_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T04:22:00.538737Z","iopub.execute_input":"2026-01-11T04:22:00.539031Z","iopub.status.idle":"2026-01-11T04:22:00.548654Z","shell.execute_reply.started":"2026-01-11T04:22:00.539008Z","shell.execute_reply":"2026-01-11T04:22:00.547740Z"}},"outputs":[{"name":"stdout","text":"/kaggle//input/bash-8-0-round-2/train.csv\n/kaggle//input/bash-8-0-round-2/test.csv\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'Headline', 'Importance Score', 'Lead Types', 'Power Mentions',\n       'Agencies', 'Reasoning', 'Key Insights', 'Tags', 'Source File'],\n      dtype='object')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"text_cols = [\n    \"Headline\",\n    \"Lead Types\",\n    \"Power Mentions\",\n    \"Agencies\",\n    \"Reasoning\",\n    \"Key Insights\",\n    \"Tags\"\n]\n\nfor col in text_cols:\n    train_df[col] = train_df[col].fillna(\"\")\n    test_df[col]  = test_df[col].fillna(\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T04:22:02.614334Z","iopub.execute_input":"2026-01-11T04:22:02.615023Z","iopub.status.idle":"2026-01-11T04:22:02.654618Z","shell.execute_reply.started":"2026-01-11T04:22:02.614973Z","shell.execute_reply":"2026-01-11T04:22:02.653741Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_df[text_cols].isna().sum()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T04:22:04.900843Z","iopub.execute_input":"2026-01-11T04:22:04.901176Z","iopub.status.idle":"2026-01-11T04:22:04.935440Z","shell.execute_reply.started":"2026-01-11T04:22:04.901148Z","shell.execute_reply":"2026-01-11T04:22:04.934546Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Headline          0\nLead Types        0\nPower Mentions    0\nAgencies          0\nReasoning         0\nKey Insights      0\nTags              0\ndtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"train_df[\"combined_text\"] = train_df[text_cols].agg(\" \".join, axis=1)\ntest_df[\"combined_text\"]  = test_df[text_cols].agg(\" \".join, axis=1)\ntrain_df[\"combined_text\"].head(1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T04:22:06.713760Z","iopub.execute_input":"2026-01-11T04:22:06.714115Z","iopub.status.idle":"2026-01-11T04:22:06.930860Z","shell.execute_reply.started":"2026-01-11T04:22:06.714087Z","shell.execute_reply":"2026-01-11T04:22:06.930163Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0    Historical analysis of Arab social cohesion an...\nName: combined_text, dtype: object"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(\n    max_features=40000,\n    ngram_range=(1, 2),\n    min_df=2,\n    stop_words=\"english\"\n)\n\nX_train = tfidf.fit_transform(train_df[\"combined_text\"])\nX_test  = tfidf.transform(test_df[\"combined_text\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T04:22:08.763754Z","iopub.execute_input":"2026-01-11T04:22:08.764611Z","iopub.status.idle":"2026-01-11T04:22:15.910610Z","shell.execute_reply.started":"2026-01-11T04:22:08.764579Z","shell.execute_reply":"2026-01-11T04:22:15.909785Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny = train_df[\"Importance Score\"]\n\nX_tr, X_val, y_tr, y_val = train_test_split(\n    X_train,\n    y,\n    test_size=0.2,\n    random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T04:22:15.912222Z","iopub.execute_input":"2026-01-11T04:22:15.912618Z","iopub.status.idle":"2026-01-11T04:22:15.929174Z","shell.execute_reply.started":"2026-01-11T04:22:15.912580Z","shell.execute_reply":"2026-01-11T04:22:15.927835Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nrf = RandomForestRegressor(\n    n_estimators=500,\n    max_depth=20,\n    random_state=42,\n    n_jobs=-1\n)\n\nrf.fit(X_tr, y_tr)\n\nrf_preds = rf.predict(X_val)\nrmse_rf = mean_squared_error(y_val, rf_preds)**0.5\n\nprint(\"RF RMSE:\", rmse_rf)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T18:41:56.914582Z","iopub.execute_input":"2026-01-10T18:41:56.915191Z","iopub.status.idle":"2026-01-10T19:17:38.682942Z","shell.execute_reply.started":"2026-01-10T18:41:56.915065Z","shell.execute_reply":"2026-01-10T19:17:38.681922Z"}},"outputs":[{"name":"stdout","text":"RF RMSE: 5.75633486360735\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"\"Importance Score\" in train_df[\"combined_text\"].iloc[0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T19:17:38.684189Z","iopub.execute_input":"2026-01-10T19:17:38.684584Z","iopub.status.idle":"2026-01-10T19:17:38.691242Z","shell.execute_reply.started":"2026-01-10T19:17:38.684548Z","shell.execute_reply":"2026-01-10T19:17:38.690432Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"X_train = tfidf.fit_transform(train_df[\"combined_text\"])\nX_test  = tfidf.transform(test_df[\"combined_text\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T19:17:38.693855Z","iopub.execute_input":"2026-01-10T19:17:38.694239Z","iopub.status.idle":"2026-01-10T19:17:46.508759Z","shell.execute_reply.started":"2026-01-10T19:17:38.694206Z","shell.execute_reply":"2026-01-10T19:17:46.507302Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nrmses = []\n\nfor train_idx, val_idx in kf.split(X_train):\n    X_tr_k, X_val_k = X_train[train_idx], X_train[val_idx]\n    y_tr_k, y_val_k = y.iloc[train_idx], y.iloc[val_idx]\n\n    model = xgb.XGBRegressor(\n        n_estimators=500,\n        max_depth=6,\n        learning_rate=0.05,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        objective=\"reg:squarederror\",\n        tree_method=\"hist\",\n        random_state=42\n    )\n\n    model.fit(X_tr_k, y_tr_k)\n    preds = model.predict(X_val_k)\n    rmses.append(mean_squared_error(y_val_k, preds, squared=False))\n\nprint(\"CV RMSEs:\", rmses)\nprint(\"Mean CV RMSE:\", np.mean(rmses))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T19:17:46.509938Z","iopub.execute_input":"2026-01-10T19:17:46.510286Z","iopub.status.idle":"2026-01-10T19:17:46.529734Z","shell.execute_reply.started":"2026-01-10T19:17:46.510258Z","shell.execute_reply":"2026-01-10T19:17:46.528533Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2624167724.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my_tr_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     model = xgb.XGBRegressor(\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"],"ename":"NameError","evalue":"name 'xgb' is not defined","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nrmses = []\n\nfor train_idx, val_idx in kf.split(X_train):\n    X_tr_k, X_val_k = X_train[train_idx], X_train[val_idx]\n    y_tr_k, y_val_k = y.iloc[train_idx], y.iloc[val_idx]\n\n    model = xgb.XGBRegressor(\n        n_estimators=800,\n        max_depth=6,\n        learning_rate=0.5,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        objective=\"reg:squarederror\",\n        tree_method=\"hist\",\n        random_state=42\n    )\n\n    model.fit(X_tr_k, y_tr_k)\n    preds = model.predict(X_val_k)\n    rmses.append(mean_squared_error(y_val_k, preds, squared=False))\n\nprint(\"CV RMSEs:\", rmses)\nprint(\"Mean CV RMSE:\", np.mean(rmses))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T19:17:46.530555Z","iopub.status.idle":"2026-01-10T19:17:46.530856Z","shell.execute_reply.started":"2026-01-10T19:17:46.530719Z","shell.execute_reply":"2026-01-10T19:17:46.530737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({'id': test['id'], 'Importance Score': np.clip(preds, 0, 100)})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Saved 'submission.csv'\")\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T19:17:46.532613Z","iopub.status.idle":"2026-01-10T19:17:46.532952Z","shell.execute_reply.started":"2026-01-10T19:17:46.532810Z","shell.execute_reply":"2026-01-10T19:17:46.532828Z"}},"outputs":[],"execution_count":null}]}